{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nose.tools import *\n",
    "# Write your imports in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d039f396633a8cf36a67ce20f8f54f92",
     "grade": false,
     "grade_id": "cell-3a5c071a139ade21",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Improvement Lab\n",
    "## Comparing and selecting models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read the data (1 point)\n",
    "Like in the previous lab, you need to read the Portuguese bank dataset [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00222/). It has been provided for you in the `data` folder.\n",
    "\n",
    "Read the dataset using `pandas` (you can use the library with the alias `pd`). Save it in the `bank_data` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70adadb2db1d50ea6b4e9cb6666d1591",
     "grade": false,
     "grade_id": "cell-39fe3843121d7b36",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bank_data = None\n",
    "bank_data = pd.read_csv(\"data/bank.csv\", delimiter=\";\")\n",
    "#bank_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f00b10cc9ad8fc21f45d20e1373e3535",
     "grade": true,
     "grade_id": "cell-b183f83b98f16a29",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# From now on, all test cells might contain hidden tests. If you follow the instructions correctly, \n",
    "# your solution will be graded with maximum points\n",
    "assert_is_not_none(bank_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess the data (1 point)\n",
    "Separate explanatory features from labels. Save all features (16 columns total) in the variable `bank_features`. Save the labels (corresponding to the `y` column) in the `bank_labels` variable. Rewrite the labels to be `0` and `1` instead of `no` and `yes`: `bank_labels` should be a numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c421bf7d581510450603999bfc030a6",
     "grade": false,
     "grade_id": "cell-fb1c7a38947afc06",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bank_features, bank_labels = None, None\n",
    "bank_features = bank_data.loc[:, bank_data.columns != \"y\"]\n",
    "bank_labels = bank_data[\"y\"].map({\"yes\" : 1, \"no\" : 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcc4b10392f16f208795d51b6e874609",
     "grade": true,
     "grade_id": "cell-30a215c478663fb9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(bank_features)\n",
    "assert_is_not_none(bank_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get indicator variables (1 point)\n",
    "Get indicator (dummy) variables for all categorical columns in `bank_features`. Overwrite the `bank_features` variable to store the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e6aee40545e1af1bac39321a0c90a6e",
     "grade": false,
     "grade_id": "cell-8724b6857c2eb7fc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bank_features = pd.get_dummies(bank_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2495d15c594a710b8dad330b65d354cb",
     "grade": true,
     "grade_id": "cell-c2b2c0bd2d30ea5e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(bank_features.shape, (4521, 51))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split the data (1 point)\n",
    "Split the data into training and testing set, with 70% of the data for training. Because the output labels are not equaly distributed, use stratification based on the `bank_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aaf739ef404c16f6b9c2c4468949a095",
     "grade": false,
     "grade_id": "cell-f46c32bb67654092",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bank_features_train, bank_labels_train = None, None\n",
    "bank_features_test, bank_labels_test = None, None\n",
    "bank_features_train, bank_features_test, \\\n",
    "bank_labels_train, bank_labels_test = train_test_split(bank_features,\n",
    "                                                       bank_labels,\n",
    "                                                       train_size = 0.7)\n",
    "#print(bank_features_train.shape)\n",
    "#print(bank_features_test.shape)\n",
    "#print(bank_labels_train.shape)\n",
    "#print(bank_labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1153f7f71bb7685f34478d8dbc30dcbb",
     "grade": true,
     "grade_id": "cell-b14f41fb226c0f37",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(bank_features_train)\n",
    "assert_is_not_none(bank_labels_train)\n",
    "assert_is_not_none(bank_features_test)\n",
    "assert_is_not_none(bank_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train a baseline algorithm (1 point)\n",
    "Train a logistic regression using the training data. Use 1 000 000 (`1e6`) as the value of C. Score it using the testing data. Save the score in the `baseline_score` variable. You should see a fairly high score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2e29d9d462d4e3df7795b4531b93a46",
     "grade": false,
     "grade_id": "cell-2fd7633e6266fcba",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "baseline_score = None\n",
    "\n",
    "model = LogisticRegression(C = 1e6)\n",
    "model.fit(bank_features_train, bank_labels_train)\n",
    "baseline_score = model.score(bank_features_test, bank_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f46cd7e4eedea45a419955afb793000a",
     "grade": true,
     "grade_id": "cell-a3af8c95790cccc4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(model)\n",
    "assert_greater(baseline_score, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Select a better score (2 points)\n",
    "As you already saw, the positive examples are very few. If you aren't convinced, just check the counts.\n",
    "\n",
    "We know that the default scoring (accuracy) isn't correct in this case. Better measures would be precision and recall. However, we only want one number. Evaluate the algorithm once again, using a standard scoring method which combines precision and recall. Overwrite the `baseline_score` variable.\n",
    "\n",
    "Don't forget to score the model on the testing data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01778fd332c624d8bffc6f0c9dd70ee2",
     "grade": false,
     "grade_id": "cell-9b44f24da39ba641",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2735849056603774"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_bank_labels = model.predict(bank_features_test)\n",
    "baseline_score = f1_score(bank_labels_test, predicted_bank_labels)\n",
    "baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "165db080ab7b1d71abc3b4e4da454237",
     "grade": true,
     "grade_id": "cell-9f4aca08f036d9de",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_less(baseline_score, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Tune your model (2 points)\n",
    "Fine-tune the `C` and `max_iter` parameters.\n",
    "\n",
    "Use full grid search with the following values:\n",
    "* `C`: 0.0001, 0.01, 0.1, 1, 10, 100, 10000\n",
    "* `max_iter`: 50, 100, 300, 1000\n",
    "* `fit_itercept`: True, False\n",
    "\n",
    "Save the grid search result in the `grid_search` variable. Don't forget to use the better scoring model that you obtained in the previous task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "440dec2d88ea0f235732de7188bf6418",
     "grade": false,
     "grade_id": "cell-88cb1341dfd72476",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.147624648604406, tolerance: 0.026748636902409972\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0650519021998264, tolerance: 0.026672619517977066\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9161495543832245, tolerance: 0.02498024496246547\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83.94650744718892, tolerance: 0.02498024496246548\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.53146273746743, tolerance: 0.025136927330173798\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71.84441455754916, tolerance: 0.026748636902409972\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.16495416066861, tolerance: 0.026672619517977066\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.44808177144391, tolerance: 0.02498024496246547\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.157189705086381, tolerance: 0.02498024496246548\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.297204012648649, tolerance: 0.025136927330173798\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.092972259429672, tolerance: 0.026748636902409972\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.000238495800602, tolerance: 0.026672619517977066\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3335242032293593, tolerance: 0.02498024496246547\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.6192090271628103, tolerance: 0.02498024496246548\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.1542296286263536, tolerance: 0.025136927330173798\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.34718225854993534, tolerance: 0.02498024496246547\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.47424070393461193, tolerance: 0.02498024496246548\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 91.86911051404283, tolerance: 0.0304\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 93.84586032449081, tolerance: 0.0303\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86.81350328165102, tolerance: 0.0281\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88.27911664083005, tolerance: 0.0281\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86.80847054431325, tolerance: 0.028300000000000002\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 91.79526949155802, tolerance: 0.0304\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 93.77195907898623, tolerance: 0.0303\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86.74067725569685, tolerance: 0.0281\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88.20044074723454, tolerance: 0.0281\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86.70799420319265, tolerance: 0.028300000000000002\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 89.86501864034061, tolerance: 0.0304\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88.20580611154202, tolerance: 0.0303\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 84.09584563045749, tolerance: 0.0281\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78.20338528637635, tolerance: 0.0281\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80.99818667914397, tolerance: 0.028300000000000002\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.813289192733777, tolerance: 0.0304\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 84.93222839006263, tolerance: 0.0303\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.46293550040685, tolerance: 0.0281\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86.72005367817499, tolerance: 0.0281\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.01712323451423, tolerance: 0.028300000000000002\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12205784783230911, tolerance: 0.02498024496246548\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05480650437442591, tolerance: 0.025136927330173798\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100.71194205003512, tolerance: 0.0304\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.45849107694957, tolerance: 0.0303\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75.35353986031677, tolerance: 0.0281\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.0365441599648, tolerance: 0.0281\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.52322056894423, tolerance: 0.028300000000000002\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2443768556574355, tolerance: 0.0304\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83.14951912207177, tolerance: 0.0303\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.333972084649218, tolerance: 0.0281\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.654319125803397, tolerance: 0.0281\n",
      "  positive)\n",
      "/home/lubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.25584509950852, tolerance: 0.0363\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                                  l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                                  positive=False, precompute=False,\n",
       "                                  random_state=None, selection='cyclic',\n",
       "                                  tol=0.0001, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [0.0001, 0.01, 0.1, 1, 10, 100, 10000],\n",
       "                         'fit_intercept': [True, False],\n",
       "                         'max_iter': [50, 100, 300, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = None\n",
    "parameters = {\n",
    "    \"alpha\": [1e-4, 1e-2, 1e-1, 1, 10, 100, 10000],\n",
    "    \"max_iter\": [50, 100, 300, 1000],\n",
    "    \"fit_intercept\": [True, False]\n",
    "}\n",
    "grid_search = GridSearchCV(ElasticNet(), param_grid = parameters)\n",
    "grid_search.fit(bank_features_train, bank_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "223a8e79f78f99698c22576177f73246",
     "grade": true,
     "grade_id": "cell-0e7311dbe13cf894",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(grid_search)\n",
    "assert_is_not_none(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Compare scores (1 point)\n",
    "Use the best estimator from your grid search. Score it using the function from problem 6. Save your answer in `tuned_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fba4251ac051f0c64db5120dbff669ef",
     "grade": false,
     "grade_id": "cell-98568f584f6c0778",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=0.0001, copy_X=True, fit_intercept=False, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_estimator_)\n",
    "tuned_score = None\n",
    "tuned_model = LogisticRegression(C = grid_search.best_estimator_.alpha, \n",
    "                                 max_iter = grid_search.best_estimator_.max_iter,\n",
    "                                 fit_intercept = grid_search.best_estimator_.fit_intercept)\n",
    "tuned_model.fit(bank_features_train, bank_labels_train)\n",
    "tuned_predicted_bank_labels = tuned_model.predict(bank_features_test)\n",
    "tuned_score = f1_score(bank_labels_test, tuned_predicted_bank_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35a694994c064d85c6ec4e0850cc87e2",
     "grade": true,
     "grade_id": "cell-545b4d41fef4eeef",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15920398009950248\n"
     ]
    }
   ],
   "source": [
    "print(tuned_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11438092556087492\n"
     ]
    }
   ],
   "source": [
    "print(baseline_score - tuned_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmm, it seems we have not obtained a better algorithm, even the opposite (the difference is marginal and depends on the random initialization of the cross-validation datasets).\n",
    "\n",
    "We can, of course, do a lot more things to improve our model's performance, such as normalizing the data, feature selection and feature engineering, trying out different aspects, e.g. polynomial terms, RANSAC; even boosting (we'll talk about this later). However, we'll stop at this point.\n",
    "\n",
    "What can we conclude? It seems that this is close to the best performance we can get out of this algorithm, given these data points.\n",
    "\n",
    "We can try improving (cleaning) our dataset, selecting features, etc. but we most likely need a better algorithm. In the next labs, we're going to explore that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
